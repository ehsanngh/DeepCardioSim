{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data_loading import load_dataset_for_gino\n",
    "from deepcardio.meshdata import BipartiteData\n",
    "import torch\n",
    "from deepcardio.losses import LpLoss, H1Loss\n",
    "\n",
    "dltrain, dltest, data_processor = load_dataset_for_gino(\n",
    "    folder_path='../data_processed/data.pt',\n",
    "    train_batch_sizes=[1], test_batch_sizes=[1, 1], use_distributed=False,\n",
    "    dataset_format=BipartiteData)\n",
    "\n",
    "dltrain\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_processor = data_processor.to(device)\n",
    "\n",
    "l2loss = LpLoss(d=3, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = l2loss\n",
    "eval_losses={'l2': l2loss}\n",
    "\n",
    "from gino import GINO\n",
    "model = GINO(\n",
    "    in_channels=5,  # [ploc_bool, D_iso, ef_vector]\n",
    "    out_channels=1,\n",
    "    gno_coord_dim=3,\n",
    "    gno_coord_embed_dim=16,\n",
    "    gno_radius=0.1,\n",
    "    gno_transform_type='linear',\n",
    "    fno_n_modes=[16, 16, 16, 1],  # x_1, x_2, x_3, t\n",
    "    fno_hidden_channels=64,\n",
    "    fno_use_mlp=True,\n",
    "    fno_norm='instance_norm',\n",
    "    fno_ada_in_features=32,\n",
    "    fno_factorization='tucker',\n",
    "    fno_rank=0.4,\n",
    "    fno_domain_padding=0.125,\n",
    "    fno_mlp_expansion=1.0,\n",
    "    fno_output_scaling_factor=1,\n",
    ")\n",
    "\n",
    "best_train_state = torch.load('ckpt/best_model_snapshot_dict.pt', map_location='cpu', weights_only=False)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(best_train_state['MODEL_STATE'])\n",
    "data_processor.eval()\n",
    "print(f\"EPOCH: {best_train_state[\"CURRENT_EPOCH\"]}, LOSS: {best_train_state[\"BEST_LOSS\"]}\")\n",
    "data_processor.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcardio.neuralop_core.utils import count_model_params\n",
    "count_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "save_dir = Path('./ckpt/')\n",
    "with open(save_dir.joinpath('metrics_dict.json').as_posix(), 'r') as f:\n",
    "    list_epoch_metrics = json.load(f)\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for metrics_data in list_epoch_metrics:\n",
    "    epochs.append(metrics_data['epoch'])\n",
    "    training_losses.append(metrics_data['avg_loss'])\n",
    "    test_losses.append(metrics_data['0_l2'])\n",
    "\n",
    "plt.plot(epochs, training_losses, label=\"Training\")\n",
    "plt.plot(epochs, test_losses, label=\"Validation\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dltrain[0].dataset):\n",
    "    if sample['label'] == '0':\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltrain[0].dataset[1863]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "for sample in dltest[0]:\n",
    "    sample = data_processor.preprocess(sample)\n",
    "    output = model(**sample)\n",
    "    output, sample = data_processor.postprocess(output, sample)\n",
    "    test_loss = l2loss(output, sample['y']).item()\n",
    "    val_losses.append(test_loss)\n",
    "    del sample, output\n",
    "    torch.cuda.empty_cache()\n",
    "plt.plot(val_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(val_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(torch.tensor(val_losses), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "for sample in dltest[1]:\n",
    "    sample = data_processor.preprocess(sample)\n",
    "    output = model(**sample)\n",
    "    output, sample = data_processor.postprocess(output, sample)\n",
    "    test_loss = l2loss(output, sample['y']).item()\n",
    "    test_losses.append(test_loss)\n",
    "    del sample, output\n",
    "    torch.cuda.empty_cache()\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(test_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "109, 505, 986, 620, 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dltest[0].dataset[174]\n",
    "sample['label'], val_losses[174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_processor.preprocess(sample)\n",
    "output = model(**sample)\n",
    "output, sample = data_processor.postprocess(output, sample)\n",
    "y = sample['y'].cpu()\n",
    "output = output.detach().cpu()\n",
    "error = torch.linalg.vector_norm(\n",
    "    torch.flatten(output, start_dim=2) - torch.flatten(y, start_dim=2),\n",
    "    ord=2, dim=-1, keepdim=True) / torch.linalg.vector_norm(\n",
    "        torch.flatten(y, start_dim=2), ord=2, dim=-1, keepdim=True)\n",
    "num_timesteps = y.shape[1]\n",
    "data_points = sample['input_geom'].cpu()\n",
    "case_ID = sample['label']\n",
    "# del sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "meshfile = '../data/mesh/case' + case_ID + '.vtk'\n",
    "xdmffile = './results/xdmf/case' + case_ID + '.xdmf'\n",
    "\n",
    "mesh = meshio.read(meshfile)\n",
    "meshio_points = mesh.points\n",
    "cells = mesh.cells_dict[\"tetra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "tree = cKDTree(data_points)\n",
    "distances, indices = tree.query(meshio_points)\n",
    "\n",
    "reordered_y = y[indices]\n",
    "reordered_error = error[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with meshio.xdmf.TimeSeriesWriter(xdmffile) as writer:\n",
    "    writer.write_points_cells(mesh.points, mesh.cells)\n",
    "    for i in range(num_timesteps):\n",
    "      data1 = reordered_y[:, i, 0].numpy()\n",
    "      data2 = output[indices][:, i, 0].numpy()\n",
    "      data3 = reordered_error[:, i, 0].numpy()\n",
    "      data4 = sample['a'][indices, i, 0].cpu().numpy()\n",
    "      data5 = sample['a'][indices, i, 1].cpu().numpy()\n",
    "      data6 = sample['a'][indices, i, 2:].cpu().numpy()\n",
    "      writer.write_data(\n",
    "         i, point_data={\"y_true\": data1,\n",
    "                        \"y_est\": data2,\n",
    "                        \"error\": data3,\n",
    "                        \"ploc_bool\": data4,\n",
    "                        \"D_iso\": data5,\n",
    "                        \"ef\": data6})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

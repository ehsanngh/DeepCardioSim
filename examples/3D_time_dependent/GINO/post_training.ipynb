{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data_loading import load_dataset_gino\n",
    "import torch\n",
    "from deepcardio.losses import LpLoss, H1Loss\n",
    "\n",
    "dltrain, dltest, data_processor = load_dataset_gino(\n",
    "    folder_path='../data/npy',\n",
    "    train_batch_sizes=[1], test_batch_sizes=[1], query_res=[32, 32, 32],\n",
    "    use_distributed=False)\n",
    "\n",
    "del dltrain\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "data_processor = data_processor.to(device)\n",
    "\n",
    "l2loss = LpLoss(d=3, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = l2loss\n",
    "eval_losses={'l2': l2loss}\n",
    "\n",
    "from gino import GINO\n",
    "model = GINO(\n",
    "    in_channels=3,  # [dr_bl, nm_bl, src_trm]\n",
    "    out_channels=1,\n",
    "    gno_coord_dim=3,\n",
    "    gno_coord_embed_dim=16,\n",
    "    gno_radius=0.1,\n",
    "    gno_transform_type='linear',\n",
    "    fno_n_modes=[16, 16, 16, 16],  # x_1, x_2, x_3, t\n",
    "    fno_hidden_channels=32,\n",
    "    fno_use_mlp=True,\n",
    "    fno_norm='instance_norm',\n",
    "    fno_ada_in_features=32,\n",
    "    fno_factorization='tucker',\n",
    "    fno_rank=0.4,\n",
    "    fno_domain_padding=0.125,\n",
    "    fno_mlp_expansion=1.0,\n",
    "    fno_output_scaling_factor=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('ckpt/model_snapshot_dict.pt', map_location='cpu', weights_only=False)['MODEL_STATE'])\n",
    "data_processor.eval()\n",
    "data_processor.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcardio.neuralop_core.utils import count_model_params\n",
    "count_model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "save_dir = Path('./ckpt/')\n",
    "with open(save_dir.joinpath('metrics_dict.json').as_posix(), 'r') as f:\n",
    "    list_epoch_metrics = json.load(f)\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for metrics_data in list_epoch_metrics:\n",
    "    epochs.append(metrics_data['epoch'])\n",
    "    training_losses.append(metrics_data['avg_loss'])\n",
    "    test_losses.append(metrics_data['0_l2'])\n",
    "\n",
    "plt.plot(epochs, training_losses)\n",
    "plt.plot(epochs, test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "for sample in dltest[0]:\n",
    "    sample = data_processor.preprocess(sample)\n",
    "    output = model(**sample)\n",
    "    output, sample = data_processor.postprocess(output, sample)\n",
    "    test_loss = l2loss(output, sample['y']).item()\n",
    "    test_losses.append(test_loss)\n",
    "    del sample, output\n",
    "    torch.cuda.empty_cache()\n",
    "plt.plot(test_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dltest[0].dataset[3]\n",
    "sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_processor.preprocess(sample)\n",
    "output = model(**sample)\n",
    "output, sample = data_processor.postprocess(output, sample)\n",
    "y = sample['y'].cpu()\n",
    "output = output.detach().cpu()\n",
    "error = torch.abs(output - y) / y.max()\n",
    "num_timesteps = y.shape[1]\n",
    "data_points = sample['input_geom'].cpu()\n",
    "case_ID = sample['label']\n",
    "del sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "meshfile = '../data/mesh/case_ID_' + case_ID + '.msh'\n",
    "xdmffile = './results/xdmf/case_ID_' + case_ID + '.xdmf'\n",
    "\n",
    "mesh = meshio.read(meshfile)\n",
    "meshio_points = mesh.points\n",
    "cells = mesh.cells_dict[\"tetra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "tree = cKDTree(data_points)\n",
    "distances, indices = tree.query(meshio_points)\n",
    "\n",
    "reordered_y = y[indices]\n",
    "reordered_error = error[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with meshio.xdmf.TimeSeriesWriter(xdmffile) as writer:\n",
    "    writer.write_points_cells(mesh.points, mesh.cells)\n",
    "    for i in range(num_timesteps):\n",
    "      t = i / 5\n",
    "      data1 = reordered_y[:, i, 0].numpy()\n",
    "      data2 = reordered_error[:, i, 0].numpy()\n",
    "      writer.write_data(t, point_data={\"y\": data1, \"error\":data2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
